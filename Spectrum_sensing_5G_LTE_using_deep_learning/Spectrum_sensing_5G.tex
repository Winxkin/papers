\documentclass[journal]{IEEEtran} % use the `journal` option for ITherm conference style
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.

\usepackage{hyperref}
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}

\graphicspath{{img/}}

\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\begin{document}

\title{Enhanced Spectrum Sensing Techniques for 5G New Radio (NR) and Long-Term Evolution (LTE) Utilizing Unet++ Deep Learning Network\\
% delete or comment-out the following line before submission
% {\footnotesize \textsuperscript{*}Note: Sub-titles are not captured in Xplore and should not be used}
% \thanks{Identify applicable funding agency here. If none, delete this.}
}

\author{%%%% author names
    \IEEEauthorblockN{\textsuperscript{1} Huan Nguyen-Duy}% first author
    , \IEEEauthorblockN{\textsuperscript{2} Dr.Thien Huynh-The}% delete this line if not needed
    %, \IEEEauthorblockN{\textsuperscript{} who ?}% delete this line if not needed
    % duplicate the line above as many times as needed to list all authors
    \\%%%% author affiliations
    \IEEEauthorblockA{\textsuperscript{1, 2}\textit{Ho Chi Minh City University of Technology and Education (HCMUTE), Vietnam}}\\% first affiliation
    \IEEEauthorblockA{\textsuperscript{1, 2}\textit{The Intelligent Multimedia and Advanced Computing (IMAC) Laboratory}}\\% delete this line if not needed
    % duplicate the line above as many times as needed to list all affiliations
    %%%% corresponding author contact details
    \IEEEauthorblockA{\textsuperscript{1}huan2931@gmail.com} \\
    \IEEEauthorblockA{\textsuperscript{2}thienht@hcmute.edu.vn}
}

\maketitle

\begin{abstract}
    The 5G New Radio (NR) technology emerged in several recent years that  is the latest generation in wireless communication technology. The 5G New Radio offers significantly higher the peak data range, high-frequency, and low-latency comparing to Long-Term Evolution (LTE). Both of them can be distinguished by the frequency range of spectrum extraction. In the recent year, the deep learning network domain introduced various cutting-edge approaches to tackle image processing in several applications such as the medical identify, spectrum sensing in signal processing, and automotive industry that utilize image segmentation techniques. In this paper, we propose the cutting-edge deep learning network base on Unet++ to enhance spectrum sensing for 5G New Radio (NR) and Long-Term Evolution (LTE) that incorporated by Unet++ and attention gate. In detail, we replaced traditional convolution by group convolution to reduce dramatically parameters of own network, around 50 percentage comparing with original Unet++ network, attention gates are applied into each skip connection to focus on the essential segmentation region in the small image. We utilize the spectrum of 5GNR and LTE dataset which were generated by MatLab 5G toolbox to evaluate own network, compare with other DeepLabv3++ and original Unet models. The accuracy of own network reached at XXX\% that is higher than DeepLabv3++, Unet, Unet++ by xx\%, yy\%, zz\%. Our implementation and pre-trained model are available at:
    \href{https://github.com/Winxkin/Spectrum_sensing_base_on_Deep_learning.git}{Spectrum sensing base on deep learning Github project}
\end{abstract}

\begin{IEEEkeywords}
    spectrum sensing, 5G New Radio (5G NR), Long-Term Evolution (LTE), Unet, unet++, deep learning network, attention gate, group convolution, semantic image segmentation, signal processing
\end{IEEEkeywords}

\section{Introduction}
The 5G New Radio (NR) is the next generation of cellular network technologies, it provides the high transmission data rage and fast transmission in kinds of different frequencies that include low-bandwidth, middle-bandwidth, and high-bandwidth \cite{b7}. In particular, low-bandwidth and middle-bandwidth are popular in many countries, 3400 to 3800 MHz in Europe, 3300 to 4990 MHz in China, 3600 MHz to 4900 MHz in Japan, 3400 MHz to 3700 MHz in Korea, and 3700 MHz to 4200 MHz in United States. The 5G NR offers the long range of frequencies than fourth Long-Term Evolution (LTE), 5G NR offers a broader spectrum range, spanning from below 1GHz up to 52.6GHz, whereas LTE typically operates within the 3.5GHz to 5GHz range.
\\
\indent
In contemporary times, the demand for wireless communication network by utilizing the limited spectrum resource increased dramatically in the recent year, it requires a fast recognition for kinds of wireless radio to apply into minimal electronic devices. In the last decade, several solutions had been proposed to discriminate the type of spectrum in wireless communication network. The paper "Intelligent Spectrum Sensing with ConvNet for 5G and LTE Signals Identification”\cite{b1} introduced a innovative methodology that utilizing deep learning network which is ConvNet built by incorporating DeepLabv3+ (an efficient encode-decoder architecture for pixel-level classification) and ResNet18 (as a backbone network for feature extraction). As the result, it reached outstanding results with global accuracy 75\% and 95\% at signal-to-noise ratio 40db and 60db respectively \cite{b1}, comparing to global accuracy 78\% and 97\% at signal-to-noise ratio 40db and 60db, respectively that using the enhance DeepLabV3+, which was showed by "Accurate Spectrum Sensing with Improved DeepLabV3+ for 5G-LTE Signals Identification" \cite{b2}.
\\
\indent
In the recent year, The deep learning network industry witnessed the development process of semantic segmentation, numerous robust encoder-decoder deep learning network was introduced for semantic segmentation domain that opened opportunities in image processing field, high precision together with light weight that have ability adapt to minimal electronic devices, contributing to numerous applications related to Biomedical
Image Segmentation \cite{b5}, signal processing \cite{b1} \cite{b2}, and medical Identification. To begin with a light weight semantic image segmentation deep learning network, Unet convolution network for Biomedical image segmentation was presented by Computer Science Department and BIOSS Center for Biological Signaling Studies, University of Freiburg, Germany in 2015 \cite{b5}. Unet was built by multiple scale convolution networks including two path encoder and decoder from high-scale to small-scale image and small-scale image to high-scale image connected to encoder path and decoder path respectively. In 2020, Unet++ is a redesigning skip connection to exploit multiple scales features in image segmentation that was presented by Zongwei Zhou \cite{b6}. Unet++ offered a higher accuracy than traditional Unet network by utilizing skip connection in each layer, the space between layers was replaced by deep convolution blocks that aim increase features extraction in the output of the network. However, these lead to increase the size of the network dramatically, the total parameters of Unet++ increased approximately fourth times comparing to traditional Unet network. \cite{b6}.
\\
\indent
In this paper, we presented innovative methodologies to enhance Unet++ deep learning network to tackle spectrum sensing 5G New Radio (NR) and Long-Term Evolution (LTE) base on received spectrum in frequency domain by the discrete Fourier transform. To begin with, we utilize group convolutions \cite{b9} to reduce dramatically size of the network, it not only has vital role in reducing the total of parameters but also retain a robust accuracy. On the other hand, attention mechanism was introduce in "Attention Is All You Need" \cite{b4}, which created a renovation in the deep learning domain in general and semantic image segmentation in Specific. In particular, Attention mechanism focus on the mainly regions in the image where need to discriminate segment of objects. Therefore, attention blocks have a light weight which plays a vital role for development deep learning network in compact power devices, especially in signal processing where numerous applications were deployed in smartphones, laptops, and others to discriminate the type of received signals that requires minimum computing performance. Thank to attention mechanism, the attention gate mechanism was introduced in "Attention U-Net: Learning Where to Look for the Pancreas" \cite{b3} by Biomedical Image Analysis Group, Imperial College London, London, UK in 2008, which enhances the discriminated ability of Unet network. In detail, attention gates adapted to skip connection in each layer of Unet network, it filter the features propagated through the skip connections \cite{b3}. The achievement of attention gates is focusing on extracted features in the same size at the corresponding layer, incorporating skip connections and lower layers by concatenation. As the result, this method showed effectively semantic image segmentation in classification and regression tasks \cite{b3}. Finally, we utilized incorporated attention gates and group convolution to reduce the size of the Unet++ network and rise the accuracy through attention gates that adapted to skip connection layers to tackle spectrum sensing for the 5G New Radio (NR) and the Long-term Evolution (LTE) base on received spectrum signals. Our objectives present a new innovative deep learning network base on Unet++ architecture that has a minimal parameters comparing to previous Unet \cite{b5}, Unet++ \cite{b6}, DeepLabV3+ \cite{b2}, and Convenet \cite{b1} deep learning network.


\section{Methodology}

\subsection{Maintaining the Integrity of the Specifications}

The IEEEtran class file is used to format your paper and style the text. All margins,
column widths, line spaces, and text fonts are prescribed; please do not
alter them. You may note peculiarities. For example, the head margin
measures proportionately more than is customary. This measurement
and others are deliberate, using specifications that anticipate your paper
as one part of the entire proceedings, and not as an independent document.
Please do not revise any of the current designations.

\section{Prepare Your Paper Before Styling}
Before you begin to format your paper, first write and save the content as a
separate text file. Complete all content and organizational editing before
formatting. Please note sections \ref{AA}--\ref{SCM} below for more information on
proofreading, spelling and grammar.

Keep your text and graphic files separate until after the text has been
formatted and styled. Do not number text heads---{\LaTeX} will do that
for you.

\subsection{Abbreviations and Acronyms}\label{AA}
Define abbreviations and acronyms the first time they are used in the text,
even after they have been defined in the abstract. Abbreviations such as
IEEE, SI, MKS, CGS, ac, dc, and rms do not have to be defined. Do not use
abbreviations in the title or heads unless they are unavoidable.

\subsection{Units}
\begin{itemize}
    \item Use either SI (MKS) or CGS as primary units. (SI units are encouraged.) English units may be used as secondary units (in parentheses). An exception would be the use of English units as identifiers in trade, such as ``3.5-inch disk drive''.
    \item Avoid combining SI and CGS units, such as current in amperes and magnetic field in oersteds. This often leads to confusion because equations do not balance dimensionally. If you must use mixed units, clearly state the units for each quantity that you use in an equation.
    \item Do not mix complete spellings and abbreviations of units: ``Wb/m\textsuperscript{2}'' or ``webers per square meter'', not ``webers/m\textsuperscript{2}''. Spell out units when they appear in text: ``. . . a few henries'', not ``. . . a few H''.
    \item Use a zero before decimal points: ``0.25'', not ``.25''. Use ``cm\textsuperscript{3}'', not ``cc''.)
\end{itemize}

\subsection{Equations}
Number equations consecutively. To make your
equations more compact, you may use the solidus (~/~), the exp function, or
appropriate exponents. Italicize Roman symbols for quantities and variables,
but not Greek symbols. Use a long dash rather than a hyphen for a minus
sign. Punctuate equations with commas or periods when they are part of a
sentence, as in:
\begin{equation}
    a+b=\gamma\label{eq}
\end{equation}

Be sure that the
symbols in your equation have been defined before or immediately following
the equation. Use ``\eqref{eq}'', not ``Eq.~\eqref{eq}'' or ``equation \eqref{eq}'', except at
the beginning of a sentence: ``Equation \eqref{eq} is . . .''

\subsection{\LaTeX-Specific Advice}

Please use ``soft'' (e.g., \verb|\eqref{Eq}|) cross references instead
of ``hard'' references (e.g., \verb|(1)|). That will make it possible
to combine sections, add equations, or change the order of figures or
citations without having to go through the file line by line.

Please don't use the \verb|{eqnarray}| equation environment. Use
\verb|{align}| or \verb|{IEEEeqnarray}| instead. The \verb|{eqnarray}|
environment leaves unsightly spaces around relation symbols.

Please note that the \verb|{subequations}| environment in {\LaTeX}
will increment the main equation counter even when there are no
equation numbers displayed. If you forget that, you might write an
article in which the equation numbers skip from (17) to (20), causing
the copy editors to wonder if you've discovered a new method of
counting.

    {\BibTeX} does not work by magic. It doesn't get the bibliographic
data from thin air but from .bib files. If you use {\BibTeX} to produce a
bibliography you must send the .bib files.

    {\LaTeX} can't read your mind. If you assign the same label to a
subsubsection and a table, you might find that Table I has been cross
referenced as Table IV-B3.

{\LaTeX} does not have precognitive abilities. If you put a
\verb|\label| command before the command that updates the counter it's
supposed to be using, the label will pick up the last counter to be
cross referenced instead. In particular, a \verb|\label| command
should not go before the caption of a figure or a table.

Do not use \verb|\nonumber| inside the \verb|{array}| environment. It
will not stop equation numbers inside \verb|{array}| (there won't be
any anyway) and it might stop a wanted equation number in the
surrounding equation.

\subsection{Some Common Mistakes}\label{SCM}
\begin{itemize}
    \item The word ``data'' is plural, not singular.
    \item The subscript for the permeability of vacuum $\mu_{0}$, and other common scientific constants, is zero with subscript formatting, not a lowercase letter ``o''.
    \item In American English, commas, semicolons, periods, question and exclamation marks are located within quotation marks only when a complete thought or name is cited, such as a title or full quotation. When quotation marks are used, instead of a bold or italic typeface, to highlight a word or phrase, punctuation should appear outside of the quotation marks. A parenthetical phrase or statement at the end of a sentence is punctuated outside of the closing parenthesis (like this). (A parenthetical sentence is punctuated within the parentheses.)
    \item A graph within a graph is an ``inset'', not an ``insert''. The word alternatively is preferred to the word ``alternately'' (unless you really mean something that alternates).
    \item Do not use the word ``essentially'' to mean ``approximately'' or ``effectively''.
    \item In your paper title, if the words ``that uses'' can accurately replace the word ``using'', capitalize the ``u''; if not, keep using lower-cased.
    \item Be aware of the different meanings of the homophones ``affect'' and ``effect'', ``complement'' and ``compliment'', ``discreet'' and ``discrete'', ``principal'' and ``principle''.
    \item Do not confuse ``imply'' and ``infer''.
    \item The prefix ``non'' is not a word; it should be joined to the word it modifies, usually without a hyphen.
    \item There is no period after the ``et'' in the Latin abbreviation ``et al.''.
    \item The abbreviation ``i.e.'' means ``that is'', and the abbreviation ``e.g.'' means ``for example''.
\end{itemize}
An excellent style manual for science writers is \cite{b7}.

\subsection{Authors and Affiliations}
\textbf{The class file is designed for, but not limited to, six authors.} A
minimum of one author is required for all conference articles. Author names
should be listed starting from left to right and then moving down to the
next line. This is the author sequence that will be used in future citations
and by indexing services. Names should not be listed in columns nor group by
affiliation. Please keep your affiliations as succinct as possible (for
example, do not differentiate among departments of the same organization).

\subsection{Identify the Headings}
Headings, or heads, are organizational devices that guide the reader through
your paper. There are two types: component heads and text heads.

Component heads identify the different components of your paper and are not
topically subordinate to each other. Examples include Acknowledgments and
References and, for these, the correct style to use is ``Heading 5''. Use
``figure caption'' for your Figure captions, and ``table head'' for your
table title. Run-in heads, such as ``Abstract'', will require you to apply a
style (in this case, italic) in addition to the style provided by the drop
down menu to differentiate the head from the text.

Text heads organize the topics on a relational, hierarchical basis. For
example, the paper title is the primary text head because all subsequent
material relates and elaborates on this one topic. If there are two or more
sub-topics, the next level head (uppercase Roman numerals) should be used
and, conversely, if there are not at least two sub-topics, then no subheads
should be introduced.

\subsection{Figures and Tables}
\paragraph{Positioning Figures and Tables} Place figures and tables at the top and
bottom of columns. Avoid placing them in the middle of columns. Large
figures and tables may span across both columns. Figure captions should be
below the figures; table heads should appear above the tables. Insert
figures and tables after they are cited in the text. Use the abbreviation
``Fig.~\ref{fig}'', even at the beginning of a sentence.

\begin{table}[htbp]
    \caption{Table Type Styles}
    \begin{center}
        \begin{tabular}{|c|c|c|c|}
            \hline
            \textbf{Table} & \multicolumn{3}{|c|}{\textbf{Table Column Head}}                                                         \\
            \cline{2-4}
            \textbf{Head}  & \textbf{\textit{Table column subhead}}           & \textbf{\textit{Subhead}} & \textbf{\textit{Subhead}} \\
            \hline
            copy           & More table copy$^{\mathrm{a}}$                   &                           &                           \\
            \hline
            \multicolumn{4}{l}{$^{\mathrm{a}}$Sample of a Table footnote.}
        \end{tabular}
        \label{tab1}
    \end{center}
\end{table}

\begin{figure}[htbp]
    \centerline{\includegraphics{fig1.png}}
    \caption{Example of a figure caption.}
    \label{fig}
\end{figure}

Figure Labels: Use 8 point Times New Roman for Figure labels. Use words
rather than symbols or abbreviations when writing Figure axis labels to
avoid confusing the reader. As an example, write the quantity
``Magnetization'', or ``Magnetization, M'', not just ``M''. If including
units in the label, present them within parentheses. Do not label axes only
with units. In the example, write ``Magnetization (A/m)'' or ``Magnetization
\{A[m(1)]\}'', not just ``A/m''. Do not label axes with a ratio of
quantities and units. For example, write ``Temperature (K)'', not
``Temperature/K''.

\section*{Acknowledgment}

The preferred spelling of the word ``acknowledgment'' in America is without
an ``e'' after the ``g''. Avoid the stilted expression ``one of us (R. B.
G.) thanks $\ldots$''. Instead, try ``R. B. G. thanks$\ldots$''. Put sponsor
acknowledgments in the unnumbered footnote on the first page.

\section*{References}

Please number citations consecutively within brackets \cite{b1}. The
sentence punctuation follows the bracket \cite{b2}. Refer simply to the reference
number, as in \cite{b3}---do not use ``Ref. \cite{b3}'' or ``reference \cite{b3}'' except at
the beginning of a sentence: ``Reference \cite{b3} was the first $\ldots$''

Number footnotes separately in superscripts. Place the actual footnote at
the bottom of the column in which it was cited. Do not put footnotes in the
abstract or reference list. Use letters for table footnotes.

Unless there are six authors or more give all authors' names; do not use
``et al.''. Papers that have not been published, even if they have been
submitted for publication, should be cited as ``unpublished'' \cite{b4}. Papers
that have been accepted for publication should be cited as ``in press'' \cite{b5}.
Capitalize only the first word in a paper title, except for proper nouns and
element symbols.

For papers published in translation journals, please give the English
citation first, followed by the original foreign-language citation \cite{b6}.

\begin{thebibliography}{00}
    \bibitem{b1} {Huynh-The, Thien, et al. "Intelligent Spectrum Sensing with ConvNet for 5G and LTE Signals Identification." 2023 IEEE Statistical Signal Processing Workshop (SSP). IEEE, 2023.}
    \bibitem{b2} {Nguyen, Gia-Vuong, Ca Van Phan, and Thien Huynh-The. "Accurate Spectrum Sensing with Improved DeepLabV3+ for 5G-LTE Signals Identification." Proceedings of the 12th International Symposium on Information and Communication Technology. 2023.}
    \bibitem{b3} {Oktay, Ozan, et al. "Attention u-net: Learning where to look for the pancreas." arXiv preprint arXiv:1804.03999 (2018).}
    \bibitem{b4} {Vaswani, Ashish, et al. "Attention is all you need." Advances in neural information processing systems 30 (2017).}
    \bibitem{b5} {Ronneberger, Olaf, Philipp Fischer, and Thomas Brox. "U-net: Convolutional networks for biomedical image segmentation." Medical image computing and computer-assisted intervention–MICCAI 2015: 18th international conference, Munich, Germany, October 5-9, 2015, proceedings, part III 18. Springer International Publishing, 2015.}
    \bibitem{b6} {Zhou, Zongwei, et al. "Unet++: Redesigning skip connections to exploit multiscale features in image segmentation." IEEE transactions on medical imaging 39.6 (2019): 1856-1867.}
    \bibitem{b7} {Pirinen, Pekka. "A brief overview of 5G research activities." 1st International Conference on 5G for Ubiquitous Connectivity. IEEE, 2014.}
    \bibitem{b8} {Lin, Xingqin, and Namyoon Lee. "5G and Beyond." Cham, Switzerland: Springer Nature Switzerland AG (2021).}
    \bibitem{b9} {Krizhevsky, Alex, Ilya Sutskever, and Geoffrey E. Hinton. "Imagenet classification with deep convolutional neural networks." Advances in neural information processing systems 25 (2012).}
\end{thebibliography}
\vspace{12pt}
\color{red}
IEEE conference templates contain guidance text for composing and formatting conference papers. Please ensure that all template text is removed from your conference paper prior to submission to the conference. Failure to remove the template text from your paper may result in your paper not being published.

\end{document}
